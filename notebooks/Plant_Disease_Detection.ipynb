{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Based Plant Disease Detection System\n",
    "\n",
    "## Project Details\n",
    "- **Roll No:** 28, 29, 30, 32\n",
    "- **Problem Statement:** Classify plant leaf diseases from images using Deep Learning.\n",
    "- **Dataset:** [Plant Disease Dataset](https://www.kaggle.com/datasets/emmarex/plantdisease)\n",
    "\n",
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (80.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.2.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dnitr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pandas numpy matplotlib seaborn kagglehub opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnitr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Download\n",
    "We use `kagglehub` to download the dataset directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Resuming download from 593494016 bytes (96018674 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/emmarex/plantdisease?dataset_version_number=1 (593494016/689512690) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 658M/658M [00:15<00:00, 6.35MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\dnitr\\.cache\\kagglehub\\datasets\\emmarex\\plantdisease\\versions\\1\n",
      "1/\n",
      "    PlantVillage/\n",
      "        Pepper__bell___Bacterial_spot/\n",
      "        Pepper__bell___healthy/\n",
      "        PlantVillage/\n",
      "            Pepper__bell___Bacterial_spot/\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Check directory structure\n",
    "for root, dirs, files in os.walk(path):\n",
    "    level = root.replace(path, '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    if level < 2: # Only print top levels to avoid spam\n",
    "        for f in files[:2]:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "    if level > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "We will use `ImageDataGenerator` for data augmentation and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset root: C:\\Users\\dnitr\\.cache\\kagglehub\\datasets\\emmarex\\plantdisease\\versions\\1\\PlantVillage\n",
      "Found 33027 images belonging to 16 classes.\n",
      "Found 8249 images belonging to 16 classes.\n",
      "Classes: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'PlantVillage', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n"
     ]
    }
   ],
   "source": [
    "import json  # Added this line\n",
    "import os\n",
    "# Define parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# IMPORTANT: Adjust 'dataset_path' based on the output of the previous cell.\n",
    "# The kaggle dataset usually extracts to a specific folder. \n",
    "# Let's assume the download path contains the 'PlantVillage' or similar structure.\n",
    "# We will try to find the directory containing the class folders automatically.\n",
    "\n",
    "dataset_root = path\n",
    "# Simple heuristic to find the root containing classes (if nested)\n",
    "for root, dirs, files in os.walk(path):\n",
    "    if len(dirs) > 2: # If contains multiple class folders\n",
    "        dataset_root = root\n",
    "        break\n",
    "\n",
    "print(f\"Using dataset root: {dataset_root}\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 80/20 split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_root,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    dataset_root,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Save class names to file for the app\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building (Transfer Learning)\n",
    "Using MobileNetV2 for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = 'plant_disease_checkpoint.keras'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    # LOAD PREVIOUS PROGRESS\n",
    "    print(\"Checkpoint found! Loading existing model...\")\n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    print(\"Resumed model from checkpoint!\")\n",
    "else:\n",
    "    # BUILD FROM SCRATCH (Only if no checkpoint exists)\n",
    "    print(\"No checkpoint found. Building model from scratch...\")\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback to save the model after every epoch\n",
    "checkpoint_path = \"plant_disease_checkpoint.h5\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=False, # Saves the whole model (architecture + weights)\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,    # Only overwrites if the model improved\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10 # Increase this for better results\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=10, \n",
    "    callbacks=[checkpoint_callback] # Add this line\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Save Model\n",
    "model.save('plant_disease_model.h5')\n",
    "print(\"Model saved as plant_disease_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
